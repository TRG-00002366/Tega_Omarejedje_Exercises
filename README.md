# Data Engineering Exercises Repository

## Overview

This repository contains my complete **6-week Data Engineering training exercises**, organized by technology and learning progression.

It serves as a structured record of hands-on practice covering modern data engineering tools, distributed systems, orchestration, streaming, warehousing, and visualization.

Each folder represents a focused learning module with practical exercises and study materials.

---

## Repository Structure

```
.
├── 0-SparkFoundations
├── 1-PySpark
├── 2-SparkSQL
├── 3-Kafka
├── 4-Airflow
├── 5-Snowflake
├── 6-Visualization
└── 7-DataOps
```


---

## Purpose

This repository demonstrates:

- Progressive mastery of core data engineering technologies
- Practical implementation of distributed systems
- End-to-end pipeline design
- Streaming and batch processing workflows
- Production-level orchestration concepts

It reflects structured learning, hands-on experimentation, and applied understanding of modern data stack components.

---

## Technologies Covered

- Apache Spark
- PySpark
- SparkSQL
- Apache Kafka
- Apache Airflow
- Snowflake
- Data Visualization Tools
- DataOps Principles

---

## Author

**[Tega Oamrejedje]**  
Aspiring Data Engineer  

---

## Notes

All exercises were completed as part of an intensive 6-week structured training program focused on building strong foundations in modern data engineering.

This repository is continuously updated as I refine concepts and expand implementations.
